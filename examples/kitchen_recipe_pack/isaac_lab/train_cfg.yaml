# Training Configuration - Kitchen Pick & Place
# Generated by BlueprintRecipe

# Task settings
task_name: "kitchen_pick_place"
experiment_name: "kitchen_pick_place_training"

# Environment settings
env:
  num_envs: 1024
  episode_length: 500

# PPO Algorithm settings
algo:
  name: "PPO"
  policy:
    class_name: "ActorCritic"
    init_noise_std: 1.0
    actor_hidden_dims: [256, 256, 128]
    critic_hidden_dims: [256, 256, 128]
    activation: "elu"

  # PPO specific
  clip_param: 0.2
  entropy_coef: 0.01
  value_loss_coef: 1.0
  max_grad_norm: 1.0

  # Learning rate
  learning_rate: 3.0e-4
  lr_schedule: "adaptive"

  # Batch settings
  num_learning_epochs: 5
  num_mini_batches: 4

  # Discount
  gamma: 0.99
  lam: 0.95

# Training settings
runner:
  max_iterations: 1500
  save_interval: 100
  log_interval: 10

  # Checkpointing
  checkpoint_path: null
  resume: false

# Logging
logging:
  wandb:
    enabled: false
    project: "blueprint_recipe"
    entity: null
  tensorboard:
    enabled: true

# Reward weights
rewards:
  reaching: 1.0
  grasp_success: 10.0
  collision: -1.0
  smooth_motion: -0.01

# Domain randomization
randomization:
  enabled: true
  on_reset:
    - name: reset_object
      params:
        position_range: [-0.3, 0.3, -0.3, 0.3, 0.9, 1.0]
    - name: randomize_lighting
      params:
        intensity_range: [500.0, 2000.0]
  on_step: []
